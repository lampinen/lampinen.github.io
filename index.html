<!--DOCTYPE html-->
<html>
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XH7F2S3670"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XH7F2S3670');
</script>
<!-- Hotjar Tracking Code for https://lampinen.github.io -->
<script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:3183811,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script>
	<link rel="stylesheet" type="text/css" href="homepage.css"></link>
	<title>Andrew Lampinen</title>
</head>
<body>
	<div class="top-bar"> <!-- name, navigation-->
                <div id="name-div" class="top-bar-item">Andrew Lampinen</div>
                <div id="navigation-bar" class="top-bar-item">
                        <div class="navigation-item" id="navigation-name-spacer"></div>
                        <div class="navigation-item navigation-item-left navigation-item-active"><a href='./index.html'>About</a></div>
                        <div class="navigation-item"><a href='./publications.html'>Publications</a></div>
                        <div class="navigation-item"><a href='./media.html'>Media &#38; Talks</a></div>
                        <div class="navigation-item"><a href='./cv.pdf'>&nbsp;CV&nbsp;</a></div>
                        <div class="navigation-item"><a href='./climbing.html'>Rock Climbing</a></div>

                        <!--<div class="navigation-item"><a href='research_visualization/research_visualization.html'>Projects Visualization</a></div>-->
                        <div class="navigation-item-right">&nbsp;</div>
                </div>
		
	</div>
        <div class="main">
        <div class="info"> <!-- pic, role, links --> 
        <div id="prof-pic-div" class="info-item"><img src='./images/ThePictureofAndrewLampinen.jpg' alt='' id="prof-pic"></div>
                        <div id="role-div" class="info-item">
                        <div class="role-sub-div">Staff Research Scientist</div><div class="role-sub-div">DeepMind</div>
                        <div class="role-other-div">
                            <a href='https://x.com/AndrewLampinen'><img src='./images/Twitter_Logo_Blue.png' alt='Twitter' class='role-icon'></a>&nbsp;
                            <a href='https://bsky.app/profile/lampinen.bsky.social'><img src='./images/Bluesky_Logo.png' alt='Bluesky' class='role-icon'></a>&nbsp;
                            <a href='https://scholar.google.com/citations?user=_N44XxAAAAAJ'><img src='./images/scholar_logo.png' alt='Google Scholar' class='role-icon'></a>&nbsp;
                            <a href='https://www.semanticscholar.org/author/Andrew-Kyle-Lampinen/32322945'><img src='./images/Semantic_Scholar_logo.png' alt='Semantic Scholar' class='role-icon'></a>
                            <a href='https://infinitefaculty.substack.com/'><img src='./images/substack_logo.png' alt='Substack' class='role-icon'></a>&nbsp;
                        </div>
                        </div>
        </div>
	<div class="content">
		<p>My research interests bridge cognitive science and artificial intelligence, often with a focus on how the complex behaviors and representations of models, agents, or humans emerge from their learning experiences or data. I have particular interests in language (especially explanations) as a learning signal, the structure of internal representations and how they can be used to study or improve a system, and the effects of scale and environmental complexity on learning.</p>
                <p>Some representative lines of work include:</p>
                <ul>
                    <li>Analyzing the <a href='https://arxiv.org/abs/2412.03782'>broad spectrum of contextual capabilities in language models</a>, including understanding <a href='https://proceedings.neurips.cc/paper_files/paper/2022/hash/77c6ccacfd9962e2307fc64680fc5ace-Abstract-Conference.html'>how in-context learning emerges from simple data distributional properties</a>, and how <a href='https://arxiv.org/abs/2505.00661'>language models generalize better from information learned in context than via finetuning</a>, and why this may mean that <a href='https://arxiv.org/abs/2509.16189'>episodic retrieval helps to reuse learning experiences more flexibly</a>.</li>
                    <li>Comparing language model capabilties to those of humans, including in processing of <a href='https://arxiv.org/abs/2210.15303'>recursive grammar structures</a> (with lessons on how to perform careful comparisons), and how <a href='https://academic.oup.com/pnasnexus/article/3/7/pgae233/7712372'>language models, like humans, show content effects on logical reasoning</a>.</li>
                    <li>Examining how training data, architectures, and objectives <a href='https://proceedings.neurips.cc/paper/2020/hash/71e9c6620d381d60196ebe694840aaaa-Abstract.html'>shape model representations</a>, and how these <a href='https://arxiv.org/abs/2405.05847'>representations are biased by irrelevant properties</a>, posing challenges for interpretability and <a href='https://arxiv.org/abs/2507.22216'>neuroscience</a>.</li>
                    <li>Reviewing the interdisciplinary literatures on <a href='https://arxiv.org/abs/2310.13018'>representational alignment</a>, and exploring how <a href='http://nature.com/articles/s41586-025-09631-6'>aligning vision model representations with human semantic knowledge</a> can make them both more robust for ML applications, and better cognitive models.</li>
                    <li>Studying how explanations can support learning in <a href='https://proceedings.mlr.press/v162/lampinen22a.html'>RL agents</a> and <a href='https://aclanthology.org/2022.findings-emnlp.38/'>language models</a>, and how explanations and interventional structure in internet data could allow language models to learn about <a href='https://proceedings.neurips.cc/paper_files/paper/2023/hash/045c87def0c02e3ad0d3d849766d7f1e-Abstract-Conference.html'>causality from passive data</a>.</li>
                    <li>Exploring how <a href='https://arxiv.org/abs/1910.00571'>richer environments can improve compositional generalization</a> of grounded language agents, and attempting to <a href='https://arxiv.org/abs/2404.10179'>scale grounded language agents across many virtual environments</a>.</li>
                    <li>I also consider broader issues such as <a href='https://arxiv.org/abs/2502.20349'>how to build more generalizable cognitive models and theories</a>, <a href='https://arxiv.org/abs/2102.03406'>how we should think about symbols in AI</a> and <a href='https://psyarxiv.com/y4az2/'>how publishing fast and slow could improve the generalizability of research</a>.</li>
                </ul>
                <p>I am a Staff Research Scientist at DeepMind. I completed my PhD in Cognitive Psychology at Stanford University. Prior to that, my background is in mathematics, physics, and machine learning. In my spare time, I enjoy <a href='./climbing.html'>climbing</a>.</p>
                <p>For more information check out my <a href='./publications.html'>publications</a>, <a href='./media.html'>media &#38; talks</a>, and <a href='./cv.pdf'>CV</a>!</p>
	</div>
        </div>
</body>
</html>
